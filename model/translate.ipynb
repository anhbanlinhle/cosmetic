{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:13.915345500Z",
     "start_time": "2024-03-04T16:29:11.069310300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (2.2.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer\\pycharmprojects\\vietai-transvien\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "138203269307320b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:13.928418Z",
     "start_time": "2024-03-04T16:29:13.916356Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55eeb5c67d4d45",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Khởi tạo model dịch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c73cb97d3ffe3de",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:26.712451700Z",
     "start_time": "2024-03-04T16:29:13.926421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(50048, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(50048, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(50048, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=50048, bias=False)\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_model_name = \"VietAI/envit5-translation\"\n",
    "translate_tokenizer = AutoTokenizer.from_pretrained(translate_model_name)\n",
    "translate_model = AutoModelForSeq2SeqLM.from_pretrained(translate_model_name)\n",
    "translate_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75fc7f531db9b0e4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:26.725144300Z",
     "start_time": "2024-03-04T16:29:26.717464700Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"vi: VietAI là tổ chức phi lợi nhuận với sứ mệnh ươm mầm tài năng về trí tuệ nhân tạo và xây dựng một cộng đồng các chuyên gia trong lĩnh vực trí tuệ nhân tạo đẳng cấp quốc tế tại Việt Nam.\",\n",
    "    \"vi: Theo báo cáo mới nhất của Linkedin về danh sách việc làm triển vọng với mức lương hấp dẫn năm 2020, các chức danh công việc liên quan đến AI như Chuyên gia AI (Artificial Intelligence Specialist), Kỹ sư ML (Machine Learning Engineer) đều xếp thứ hạng cao.\",\n",
    "    \"en: Our teams aspire to make discoveries that impact everyone, and core to our approach is sharing our research and tools to fuel progress in the field.\",\n",
    "    \"en: We're on a journey to advance and democratize artificial intelligence through open source and open science.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def translate_texts(sentences):\n",
    "    outputs = translate_model.generate(translate_tokenizer(sentences, return_tensors=\"pt\", padding=True).input_ids.to('cuda'), max_length=512)\n",
    "    sentences = translate_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(sentences)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:26.736767200Z",
     "start_time": "2024-03-04T16:29:26.728139700Z"
    }
   },
   "id": "10de8ed3a002360e",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en: VietAI is a non-profit organization with the mission of nurturing artificial intelligence talents and building an international - class community of artificial intelligence experts in Vietnam.', 'en: According to the latest LinkedIn report on the 2020 list of attractive and promising jobs, AI - related job titles such as AI Specialist, ML Engineer and ML Engineer all rank high.', 'vi: Nhóm chúng tôi khao khát tạo ra những khám phá có ảnh hưởng đến mọi người, và cốt lõi trong cách tiếp cận của chúng tôi là chia sẻ nghiên cứu và công cụ để thúc đẩy sự tiến bộ trong lĩnh vực này.', 'vi: Chúng ta đang trên hành trình tiến bộ và dân chủ hoá trí tuệ nhân tạo thông qua mã nguồn mở và khoa học mở.']\n"
     ]
    }
   ],
   "source": [
    "translate_texts(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:32.021508200Z",
     "start_time": "2024-03-04T16:29:26.736767200Z"
    }
   },
   "id": "2e54a6e5910c7a17",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lưu trạng thái model dịch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "668824fad4768b5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:32.038631800Z",
     "start_time": "2024-03-04T16:29:32.023959100Z"
    }
   },
   "id": "f021a6b0d0e6cadf",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(translate_model.state_dict(), \"./translate_model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:29:34.605117200Z",
     "start_time": "2024-03-04T16:29:32.034637Z"
    }
   },
   "id": "a90c3f8c174ad2be",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "d5e68ddc4a313c6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Khởi tạo model rút gọn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212dd836c89abce4",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-04T16:29:34.607121600Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-large-vietnews-summarization\")  \n",
    "summary_model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-large-vietnews-summarization\")\n",
    "summary_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lưu trạng thái model dịch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a9ef4d52eb794a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hàm rút gọn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c87f8727fa3f7c76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def summary_text(sentence):\n",
    "    text =  \"vietnews: \" + sentence + \" </s>\"\n",
    "    encoding = summary_tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
    "    sum_outputs = summary_model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        max_length=256,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    for output in sum_outputs:\n",
    "        line = summary_tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        return line\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "759e96fb0e86ec7c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in sentences:\n",
    "    print(summary_text(i))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "21e163d6fa035bc4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
